---
post: true
title: The Great Internet Garbage Patch is Growing Larger Every Day
draft: false
tags:
  - culture
description: AI Denzel Washington motivational deepfakes are the portent of our doom
featuredimagefilename: A24VODfeaturedimage.png
permalink: 
date:
---

![[Pasted image 20240929191606.png]]

If you're someone who regularly uses the internet in their day-to-day life you've probably noticed lately it feels... worse. Not massively worse mind you, but enough to be noticeable here and there. A slightly downgraded experience affecting almost every corner of the internet.

This change became abundantly clear one day while scrolling through my TikTok feed. The app's massive push towards monetization has already turned most of my feed into a wasteland of QVC imitators, but amidst the depressing shopping livestreams and bizarre product placements I noticed a curious new trend; static images of Denzel Washington with motivational quotes narrated over the top.

The reason this caught my attention is because I'm already a big fan of Mr. Washington's work. I grew watching his films (_Fallen_ is a great movie and I will gladly die on that hill!) and I'm very familiar with the cadence of his voice and his more famous quotes. So it was immediately obvious to me that the audio of his voice was AI-generated and I was fairly certain Denzel Washington had never said this.

Then not two videos later I was confronted with another, a different Denzel picture but the exact same quote and AI audio. Curious, but not exactly unique nowadays; I see plenty of repetitive videos on my Tiktok feed nowadays during what little time I spend on the app anymore. The repetition mostly comes from different accounts all trying to sell the same gadget desperately in search of a problem to solve. But lo and behold, not a few swipes later I was looking at another Denzel picture and the same motivational quote.

https://www.tiktok.com/@empowermind8/video/7357981816680172843?is_from_webapp=1&web_id=7348508610656683562

https://www.tiktok.com/@g_s504/video/7354570923418062123?is_from_webapp=1&web_id=7348508610656683562

https://www.tiktok.com/@sharaya_sharaya/video/7351134111504928032?is_from_webapp=1&web_id=7348508610656683562

The quote itself seems to be a mashup of common tropes in motivational speeches:

_"If you're rejected, accept it. If you're unloved, let go. If they choose someone or something over you, move on. Not everyone you love will stay. Not everyone you trust will be loyal. I don't care about losing people who don't wanna be in my life anymore. I've lost people who meant the world to me and I'm still doing just fine. Do not follow the majority. Follow the right way. You can feel it when someone is not being real with you. Energy never lies. Always speak how you feel and never be sorry for being real. Give people time, give people space. Don't beg anyone to stay, let them roam. What's meant for you will always be yours. I feel so much better when people don't know where I am and what I'm doing. You may not be able to control every situation and its outcome but you can control your attitude and how you deal with it. Do good, it will come back to you in unexpected ways. Be happy with what you have while working for what you want. Remember that some things have to end for better things to begin."_

In all my internet sleuthing I didn't find any evidence Denzel Washington has ever spoken these words. In fact it looks like this quote has only existed for a few months based on the timestamps I saw while combing through TikTok videos. But I don't believe seeing all these videos at once are just mere algorithmic happenstance.

Besides this Denzel deluge I've seen similar patterns everywhere in my corner of the internet: social media feeds for every app have slightly more low-quality sponsored content and advertisements to scroll past. Friend requests from spam accounts sending phishing links or pornography are increasing in frequency. Search engine results have a little bit more junk we need to wade through to find the answers we need than they used to. Even more isolated areas of content don't seem to be immune to this onslaught (just ask the scientific community about their recent [dubious research results](https://www.404media.co/google-says-it-discovered-millions-of-new-materials-with-ai-human-researchers/) or [peer reviews](https://arxiv.org/pdf/2403.07183.pdf)). The junk and spam seeping into the internet is steadily increasing in velocity and volume and as a result I find myself spending more of my time filtering through meaningless and worthless pieces of content. Or put more simply, the internet is filling up with garbage. And more than usual.

![[Pasted image 20240929191712.png]]

It's like a For You page but with less reposts

It seems one of the more negative consequences of AI advances has finally started to rear its head. Easier access to this technology has allowed more people than ever to [start churning out low-quality content at an exponential pace](https://www.404media.co/inside-the-world-of-tiktok-spammers-and-the-ai-tools-that-enable-them/) in the never-ending pursuit of consumers, whether that's in the form of views, clicks, or likes, and the potential income that can come along with them. Not to mention the rampant disinformation and misinformation we're seeing from this content that plenty of social media users [aren't even noticing](https://www.404media.co/facebook-is-being-overrun-with-stolen-ai-generated-images-that-people-think-are-real/?ref=daily-stories-newsletter). And this is just the start, wait until AI-generated content has really whittled away at the foundations of [world history](https://marinaamaral.substack.com/p/ai-is-creating-fake-historical-photos) and other . Many publications have already written about how AI going mainstream would affect the fields of SEO and marketing, but it seems this change has finally started to impact the public-facing side of the internet as well. And the bad news is that it's only going to get worse from here.

The problem is there doesn't seem to be much anyone can or will do to head off the tidal wave of internet garbage headed our way. While AI-generated content is all the rage, tools to identify and filter this content has seen very little enthusiasm. AI detection tools have proven ineffective at best (and usually [worse](https://www.technologyreview.com/2023/07/07/1075982/ai-text-detection-tools-are-really-easy-to-fool/) or [much worse](https://arstechnica.com/information-technology/2023/07/why-ai-detectors-think-the-us-constitution-was-written-by-ai/) than that), when they aren't [being taken out of use entirely](https://www.theverge.com/2023/7/25/23807487/openai-ai-generated-low-accuracy), and that arms race will always be reacting to advances rather than proactively cleaning up. A few areas of the internet have seen successful attempts to detect and filter out AI-generated content, but only targeted very specific fields of content or use cases. Typically this has been accomplished by looking at the content against a threshold for what most likely constitutes AI patterns compared to the average person’s use of language. But this is while AI-generated content can still be laughably obvious in many cases. Will these detection tools be effective at all once it becomes almost impossible to tell the difference between content created by humans and AI through language patterns? And who is going to decide where to draw a line between these two? Language is a complex and ever-changing landscape, so adding to this complexity is that any tool created will need to be able to keep up with these changes. On top of that, who knows what kind of changes in syntax and dialect we’ll see as a result AI’s influence over the next few years?

On the opposite end of this conundrum, AI signatures are another tool being created to easily differentiate between AI-generated and human-generated content. Establishing standards to mark AI content at the source seems to be a more effective solution given the sheer volume of content being generated in so many different mediums and [efforts are already underway](https://c2pa.org/) with the support of some major players in technology. But the problem here lies in solidarity. There will always be companies refusing to opt in to standards because, either for technological or financial reasons, they can't or don't want to. And there will always be customers seeking these companies to get around those standards. And then we’re just back where we started trying to identify content generated by AI, though with at least a sizable amount of that work already done for us thanks to those standards.

Of course another avenue that could offer relief from all this garbage would be through SEO changes. If search engines update their cryptic algorithms to favor human-generated content, or trusted sites that have shown reliability and authenticity, over AI-generated content in search results that would almost certainly provide a financial incentive for companies to clean things up. But in many cases these same tech companies that rule over SEO [don't have any incentive](https://www.404media.co/google-news-is-boosting-garbage-ai-generated-articles/) to clean up an internet that they themselves are already actively polluting with AI-generated junk. And if the history of SEO changes is any indication, this effort will devolve into an endless and forth between search engines making new rules and SEO experts finding new ways to work around those same rules.

So what does all of this mean for the future of our internet? To put it simply, I think the average internet experience is going to keep seeing a steady downturn in quality until suddenly that trend accelerates and we find ourselves neck-deep in AI-generated junk. And I’m worried that like any boiling frog (not that this idiom is true at all) by the time any of us notice it will be too late to take effective action.

My fear is that two versions of the internet will emerge because of this influx of garbage. One will be a well-maintained walled garden, full of mostly pleasant actual human people and an overall enjoyable place to visit with a nice barrier keeping out most but probably not all of the junk. And the other will be a true internet hellscape: inundated with low-quality content, spewing endlessly repetitive knockoffs of original thoughts at you, [reduced to stereotypes](https://restofworld.org/2023/ai-image-stereotypes/), with fake people hawking nonsense goods & services and constant waves of spam ads knocking you down with every click. And the the only factor separating the two will be price.

![[Pasted image 20240929191729.png]]

Meet your new internets! (Not to be on the nose or anything)

Content moderation costs companies a lot of time, money, and headache depending on who finds themselves being moderated. Which is why recently we've seen some shy away from moderation in favor of a free-for-all moderation ecosystem (to dubious results I might add). But other companies are finding little alternative but to ramp up content moderation efforts leading to rising costs that cut into revenue. And these two approaches may create a digital rift between the haves and the have-nots. We’ve already seen this to some extent with the recent influx of ad-free vs. ad-supported streaming options (proving that cost is once again the ultimate deciding factor as we saw with the “free” ad-supported TV so many people signed onto). If that happens there’s going to be an economic separation of tech companies that take necessary steps to prevent this influx of low-quality AI content and the ones that don't. And my fear is that this will segregate the internet into two very distinct cultural experiences.

There isn’t a whole lot we as individual users can do to prevent this wave of garbage. I've seen some argue that the only way to effectively combat this invasion is through [government intervention and legislation](https://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html), which I agree would be a massive step in the right direction. But this AI-generated content isn’t going anymore and the tools to make it are only going to become more accessible with each passing day. Like any tech trend we’ve seen take off in the past the AI hype train has a lot of momentum, but I do think society has started to recognize enough of its inherent problems that enthusiasm has begun to dampen. Our only hope is that enough outcry, both from users and all the tech companies in this space who are going to take the brunt of the damage this influx of garbage will cause, forces AI companies to invest in effective tools to moderate and manage the flow of this mess they’ve created. But for now we will have to wade our way through this trickle of garbage and junk in the search for authentic Denzel Washington content. Just don’t be surprised when that trickle turns into something bigger.

https://www.youtube.com/watch?v=jdT2ZATYuMQ

There's a Denzel reference for every occasion, including a metaphor for the invasion of  
AI-generated garbage content on the internet.